---
title: "idcol_qaqc"
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = paste0(substr(inputFile,1,nchar(inputFile)-4),Sys.Date(),'.html')) })

output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: false
    number_sections: true
    highlight: pygments 
    theme: cosmo
    code_folding: hide
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

local_tz = "Asia/Dhaka"
source('r_scripts/load.R') #libraries
source('r_scripts/UPAS_functions.R') #functions to clean, plot, summarize
source('r_scripts/lascar_functions.R')

sample_duration_thresholds = c(1296,1584)
```

# Cleaning rules
* 

# Load UPAS data
* 
``` {r load-data, cache = TRUE,echo = FALSE}

file_list_upas <- list.files("/Users/ricardopiedrahita/Dropbox/IDCOL Bangladesh (shared)/Data/UPAS PM/Field data",
                             pattern='.txt|.TXT', full.names = T,recursive = T) %>% 
  grep("DIAGNOSTIC", ., ignore.case = TRUE, value = TRUE, invert = TRUE)  

file_list_upas = file_list_upas[sapply(file_list_upas, file.size) > 10000]

upas_data = rbindlist(lapply(file_list_upas,read_upas),fill=TRUE) 

upas_header <- rbindlist(lapply(file_list_upas,read_upas_header)) %>% 
  as.data.frame() %>% 
  dplyr::arrange(LoggedRuntime,SampledVolume) %>% 
  dplyr::mutate(filen = basename(file),
                file_start_date = as.Date(StartDateTimeUTC),
                CartridgeID = toupper(CartridgeID),
                StartDateTimeLocal = with_tz(StartDateTimeUTC, 
                                             tzone=local_tz),
                date_start = date(StartDateTimeLocal),
                sample_type = case_when(UPASlogFilename %like% "KIT|Kit|kit" ~ "Kitchen",
                                        UPASlogFilename %like% "PER|Per|per" ~ "Personal",
                                        TRUE ~ "")) %>%
  dplyr::select(-UPASfirmware,-LifetimeSampleCount,-LifetimeSampleRuntime,-GPSUTCOffset,ProgrammedStartDelay,-AppLock,-AppVersion,
                -StartOnNextPowerUp,-LogInterval,-LogFileMode,-file_start_date,-DutyCycleWindow,-GPSEnabled,-ProgrammedStartDelay,
                -StartBatteryCharge,-EndBatteryCharge,-ShutdownMode,-SampledRuntime,-VolumetricFlowRate,-FlowOffset) %>% 
  dplyr::select(file,StartDateTimeUTC,LoggedRuntime,SampledVolume,ShutdownReason,everything())

DT::datatable(upas_header,caption = "UPAS summary data")
```

# Import ODK
* Survey data is on IDCOL servers and in there own format.
```{r import_odk}


```

# Load Lascar data
```{r import_cooking}

# UPAS data import and check
lascarfilepath <- "~/Dropbox/IDCOL Bangladesh (shared)/Data/Lascar CO" 
file_list_lascar <- list.files(lascarfilepath, pattern='.txt|.TXT', full.names = T,recursive = T) # %>% 
# grep("DIAGNOSTIC", ., ignore.case = TRUE, value = TRUE, invert = TRUE)  

lascar_cali_coefs <- read_xlsx("~/Dropbox/IDCOL Bangladesh (shared)/Data/Lascar CO/Initial CO cal ests/IDCOL Lascar Calibrations_Jan2020Lascars.xlsx",skip = 1)  %>%
  dplyr::rename_all(function(x) gsub(" ","", x)) %>% 
  dplyr::rename(COslope = `CalibrationSlope[ppmLascar/ppmactual]`) %>% 
  dplyr::distinct() 


# Lascar data
lascar_meta <- ldply(file_list_lascar, lascar_qa_fun, .progress = 'text',local_tz=local_tz)  
DT::datatable(lascar_meta,caption = "Lascar data summary")

# Time series Lascar - get full time series of calibrated data, with metadata.
# Truncation is employed with the tagging approach - any non-tagged points are not from during the deployments
CO_calibrated_timeseries <- ldply(file_list_lascar, 
                                  lascar_cali_fun, .progress = 'text',local_tz=local_tz,
                                  lascar_cali_coefs = lascar_cali_coefs)  


```


# Save 
```{r savedatar}

list_of_datasets <- list(
  "UPAS"=upas_header,
  "lascar" = lascar_meta)


filename = paste0("~/Dropbox/IDCOL Bangladesh (shared)/Data/QA Reports/IDCOL_QA_Report_",  Sys.Date(), ".xlsx")
write.xlsx(list_of_datasets,file = filename)


```